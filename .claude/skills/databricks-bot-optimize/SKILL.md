---
name: databricks-bot-optimize
description: |
  æ•ˆèƒ½å„ªåŒ–åŠ©æ‰‹ã€‚æä¾›å¿«å–ã€é€£æ¥æ± ã€éåŒæ­¥ã€è¨˜æ†¶é«”å„ªåŒ–ç­–ç•¥ã€‚
  è§¸ç™¼ï¼šã€Œå„ªåŒ–ã€ã€Œæ•ˆèƒ½ã€ã€Œé€Ÿåº¦æ…¢ã€ã€Œmemoryã€ã€Œperformanceã€ã€Œå¿«å–ã€
  å¹«åŠ©æå‡æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½å’Œè³‡æºä½¿ç”¨æ•ˆç‡ã€‚
---

# DatabricksGenieBOT Performance Optimizer

æä¾›æ•ˆèƒ½å„ªåŒ–ç­–ç•¥å’Œå¯¦ä½œæŒ‡å—ï¼Œæå‡å›æ‡‰é€Ÿåº¦å’Œè³‡æºæ•ˆç‡ã€‚

## å„ªåŒ–é ˜åŸŸ

1. **HTTP é€£æ¥æ± ** - æ¸›å°‘é€£æ¥å»ºç«‹æ™‚é–“
2. **å¿«å–ç³»çµ±** - é¿å…é‡è¤‡è¨ˆç®—
3. **éåŒæ­¥è™•ç†** - æå‡ä¸¦ç™¼èƒ½åŠ›
4. **è¨˜æ†¶é«”ç®¡ç†** - é˜²æ­¢ OOM
5. **æ—¥èªŒå„ªåŒ–** - æ¸›å°‘ I/O é–‹éŠ·

---

## 1. HTTP é€£æ¥æ± å„ªåŒ–

### å•é¡Œ
æ¯æ¬¡ API å‘¼å«éƒ½å»ºç«‹æ–°é€£æ¥ï¼Œæµªè²»æ™‚é–“ã€‚

```python
# âŒ ä¸å¥½ï¼šæ¯æ¬¡å»ºç«‹æ–°é€£æ¥
async def query_api(url):
    async with httpx.AsyncClient() as client:  # æ–°é€£æ¥
        response = await client.get(url)
        return response.json()
```

**æ•ˆèƒ½å½±éŸ¿**ï¼š
- é€£æ¥å»ºç«‹æ™‚é–“ï¼š200-300ms
- TLS æ¡æ‰‹ï¼š100-200ms
- ç¸½å»¶é²ï¼š300-500ms

### è§£æ±ºæ–¹æ¡ˆ

```python
# âœ… å¥½ï¼šé‡ç”¨é€£æ¥æ± 
class APIService:
    def __init__(self):
        self._client: Optional[httpx.AsyncClient] = None

    async def _get_client(self) -> httpx.AsyncClient:
        """å–å¾—æˆ–å»ºç«‹ HTTP å®¢æˆ¶ç«¯ï¼ˆé€£æ¥æ± ï¼‰"""
        if self._client is None:
            self._client = httpx.AsyncClient(
                timeout=httpx.Timeout(
                    connect=5.0,
                    read=10.0,
                    write=10.0,
                    pool=30.0
                ),
                limits=httpx.Limits(
                    max_keepalive_connections=5,  # ä¿æŒé€£æ¥æ•¸
                    max_connections=10             # æœ€å¤§é€£æ¥æ•¸
                )
            )
        return self._client

    async def query_api(self, url: str):
        client = await self._get_client()
        response = await client.get(url)
        return response.json()

    async def close(self):
        """é—œé–‰å®¢æˆ¶ç«¯"""
        if self._client:
            await self._client.aclose()
            self._client = None
```

**æ•ˆèƒ½æå‡**ï¼š
- é¦–æ¬¡è«‹æ±‚ï¼š300msï¼ˆå»ºç«‹é€£æ¥ï¼‰
- å¾ŒçºŒè«‹æ±‚ï¼š20-30msï¼ˆé‡ç”¨é€£æ¥ï¼‰
- **æå‡ 90%**

---

## 2. å¿«å–ç³»çµ±å¯¦ä½œ

### å°ˆæ¡ˆå·²å¯¦ä½œçš„å¿«å–

```python
from app.utils.cache_utils import SimpleCache, cached_query, cached_chart

# å…¨åŸŸå¿«å–å¯¦ä¾‹
query_cache = SimpleCache(max_size=100, ttl_seconds=3600)    # 1å°æ™‚
chart_cache = SimpleCache(max_size=50, ttl_seconds=7200)     # 2å°æ™‚
```

### ä½¿ç”¨è£é£¾å™¨å¿«å–

```python
from app.utils.cache_utils import cached_query

@cached_query(cache=query_cache)
async def expensive_query(space_id: str, query: str) -> dict:
    """æ˜‚è²´çš„æŸ¥è©¢ï¼ˆæœƒè¢«å¿«å–ï¼‰"""
    result = await genie_service.query(space_id, query)
    return result

# é¦–æ¬¡å‘¼å«ï¼š1200msï¼ˆçœŸå¯¦ APIï¼‰
result1 = await expensive_query("space-1", "SELECT * FROM table")

# å¾ŒçºŒå‘¼å«ï¼š< 1msï¼ˆå¿«å–å‘½ä¸­ï¼‰
result2 = await expensive_query("space-1", "SELECT * FROM table")
```

### æ‰‹å‹•å¿«å–æ§åˆ¶

```python
from app.utils.cache_utils import SimpleCache

cache = SimpleCache(max_size=100, ttl_seconds=3600)

# è¨­å®šå¿«å–
cache_key = f"user:{user_id}:query:{query_hash}"
cache.set(cache_key, result)

# å–å¾—å¿«å–
result = cache.get(cache_key)
if result is None:
    # å¿«å–æœªå‘½ä¸­ï¼ŒåŸ·è¡ŒæŸ¥è©¢
    result = await expensive_operation()
    cache.set(cache_key, result)

# æ¸…é™¤å¿«å–
cache.clear()

# æŸ¥çœ‹çµ±è¨ˆ
stats = cache.get_stats()
print(f"å‘½ä¸­ç‡: {stats.hit_rate:.2%}")
```

---

## 3. éåŒæ­¥æœ€ä½³åŒ–

### ä¸¦ç™¼è™•ç†å¤šå€‹è«‹æ±‚

```python
import asyncio

# âŒ ä¸å¥½ï¼šåºåˆ—è™•ç†
async def process_multiple_queries_serial(queries):
    results = []
    for query in queries:
        result = await genie_service.query(query)  # ç­‰å¾…å®Œæˆ
        results.append(result)
    return results
# ç¸½æ™‚é–“ï¼šn Ã— 1200ms

# âœ… å¥½ï¼šä¸¦ç™¼è™•ç†
async def process_multiple_queries_parallel(queries):
    tasks = [
        genie_service.query(query)
        for query in queries
    ]
    results = await asyncio.gather(*tasks)  # ä¸¦ç™¼åŸ·è¡Œ
    return results
# ç¸½æ™‚é–“ï¼šmax(1200ms)
```

**æ•ˆèƒ½æå‡**ï¼š
- 10 å€‹æŸ¥è©¢åºåˆ—ï¼š12 ç§’
- 10 å€‹æŸ¥è©¢ä¸¦ç™¼ï¼š1.5 ç§’
- **æå‡ 88%**

### ä½¿ç”¨ asyncio.gather è™•ç†éŒ¯èª¤

```python
# æŸäº›ä»»å‹™å¤±æ•—æ™‚ç¹¼çºŒ
async def process_with_error_handling(queries):
    tasks = [genie_service.query(q) for q in queries]

    # return_exceptions=Trueï¼šéŒ¯èª¤ä¸æœƒä¸­æ–·å…¶ä»–ä»»å‹™
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # è™•ç†çµæœ
    successes = []
    failures = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            failures.append((queries[i], result))
        else:
            successes.append(result)

    return successes, failures
```

---

## 4. è¨˜æ†¶é«”å„ªåŒ–

### æœƒè©±è‡ªå‹•æ¸…ç†

```python
from app.utils.session_manager import cleanup_expired_sessions

# èƒŒæ™¯ä»»å‹™å®šæœŸæ¸…ç†æœƒè©±
async def session_cleanup_task():
    """èƒŒæ™¯æ¸…ç†ä»»å‹™"""
    while True:
        await asyncio.sleep(3600)  # æ¯å°æ™‚åŸ·è¡Œ
        count = await cleanup_expired_sessions(timeout_hours=4)
        logger.info(f"æ¸…ç† {count} å€‹éæœŸæœƒè©±")

# åœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚å•Ÿå‹•
asyncio.create_task(session_cleanup_task())
```

### é™åˆ¶å¿«å–å¤§å°

```python
from app.utils.cache_utils import SimpleCache

# LRU + TTL å¿«å–ï¼ˆè‡ªå‹•æ¸…ç†ï¼‰
cache = SimpleCache(
    max_size=100,      # æœ€å¤š 100 é …ï¼ˆLRU é©…é€ï¼‰
    ttl_seconds=3600   # 1 å°æ™‚éæœŸ
)

# ç•¶è¶…é max_size æ™‚ï¼Œè‡ªå‹•é©…é€æœ€å°‘ä½¿ç”¨çš„é …ç›®
```

### å¤§è³‡æ–™åˆ†é è™•ç†

```python
def process_large_dataset(data: list, chunk_size: int = 100):
    """åˆ†æ‰¹è™•ç†å¤§è³‡æ–™é›†"""
    for i in range(0, len(data), chunk_size):
        chunk = data[i:i+chunk_size]
        yield chunk

# ä½¿ç”¨
for chunk in process_large_dataset(large_data, chunk_size=100):
    process_chunk(chunk)
    # æ¯æ¬¡åªè™•ç† 100 é …ï¼Œé¿å…è¨˜æ†¶é«”çˆ†ç‚¸
```

---

## 5. æ—¥èªŒå„ªåŒ–

### å•é¡Œ
é »ç¹æ—¥èªŒ I/O å½±éŸ¿æ•ˆèƒ½ã€‚

### è§£æ±ºæ–¹æ¡ˆï¼šæ—¥èªŒæ¡æ¨£

```python
import random
import time

class SampledLogger:
    """æ¡æ¨£æ—¥èªŒè¨˜éŒ„å™¨ï¼ˆæ¸›å°‘ I/Oï¼‰"""

    def __init__(self, logger, sample_rate: float = 0.01):
        """
        Args:
            logger: æ¨™æº– logger
            sample_rate: æ¡æ¨£ç‡ï¼ˆ0.01 = 1%ï¼‰
        """
        self.logger = logger
        self.sample_rate = sample_rate
        self.last_stats_time = time.time()
        self.stats = {"total": 0, "sampled": 0}

    def info(self, message: str, force: bool = False):
        """è¨˜éŒ„ infoï¼ˆæ¡æ¨£ï¼‰"""
        self.stats["total"] += 1

        if force or random.random() < self.sample_rate:
            self.logger.info(message)
            self.stats["sampled"] += 1

        # å®šæœŸè¼¸å‡ºçµ±è¨ˆ
        if time.time() - self.last_stats_time > 60:
            self.logger.info(
                f"æ—¥èªŒçµ±è¨ˆ: {self.stats['sampled']}/{self.stats['total']} "
                f"({self.stats['sampled']/self.stats['total']*100:.1f}%)"
            )
            self.last_stats_time = time.time()
            self.stats = {"total": 0, "sampled": 0}

# ä½¿ç”¨
sampled_logger = SampledLogger(logger, sample_rate=0.01)

for i in range(1000):
    sampled_logger.info(f"è™•ç†è«‹æ±‚ {i}")  # åªè¨˜éŒ„ 1%
```

**æ•ˆèƒ½æå‡**ï¼š
- æ—¥èªŒ I/O æ¸›å°‘ 99%
- æ‡‰ç”¨ç¨‹å¼ååé‡æå‡ 15-20%

---

## 6. è³‡æ–™åº«æŸ¥è©¢å„ªåŒ–ï¼ˆDatabricksï¼‰

### æ‰¹æ¬¡æŸ¥è©¢

```python
# âŒ ä¸å¥½ï¼šå¤šæ¬¡å°æŸ¥è©¢
async def get_user_data_serial(user_ids):
    results = []
    for user_id in user_ids:
        result = await db.query(f"SELECT * FROM users WHERE id = {user_id}")
        results.append(result)
    return results
# 10 å€‹ç”¨æˆ¶ = 10 æ¬¡æŸ¥è©¢

# âœ… å¥½ï¼šå–®æ¬¡æ‰¹æ¬¡æŸ¥è©¢
async def get_user_data_batch(user_ids):
    ids_str = ','.join([f"'{uid}'" for uid in user_ids])
    query = f"SELECT * FROM users WHERE id IN ({ids_str})"
    result = await db.query(query)
    return result
# 10 å€‹ç”¨æˆ¶ = 1 æ¬¡æŸ¥è©¢
```

### ä½¿ç”¨ LIMIT

```python
# åªå–éœ€è¦çš„è³‡æ–™
query = "SELECT * FROM large_table LIMIT 100"  # é™åˆ¶çµæœæ•¸
```

---

## 7. åœ–è¡¨ç”Ÿæˆå„ªåŒ–

### å¿«å–åœ–è¡¨

```python
from app.utils.cache_utils import cached_chart

@cached_chart(cache=chart_cache)
def generate_chart(data: list, chart_type: str) -> str:
    """ç”Ÿæˆåœ–è¡¨ï¼ˆæœƒè¢«å¿«å–ï¼‰"""
    # åœ–è¡¨ç”Ÿæˆé‚è¼¯...
    return base64_image

# é¦–æ¬¡ï¼š300msï¼ˆç”Ÿæˆåœ–è¡¨ï¼‰
chart1 = generate_chart(data, "bar")

# å¾ŒçºŒï¼š< 1msï¼ˆå¿«å–å‘½ä¸­ï¼‰
chart2 = generate_chart(data, "bar")
```

### é™ä½åœ–è¡¨è§£æåº¦

```python
import matplotlib.pyplot as plt

# èª¿æ•´ DPI å¹³è¡¡å“è³ªå’Œå¤§å°
plt.savefig(
    buffer,
    format='png',
    dpi=100,  # é™ä½ DPIï¼ˆé è¨­ 150ï¼‰
    bbox_inches='tight'
)
```

---

## 8. æ•ˆèƒ½ç›£æ§

### æ¸¬é‡é—œéµæ“ä½œæ™‚é–“

```python
import time
from functools import wraps

def measure_time(operation_name: str):
    """æ¸¬é‡å‡½å¼åŸ·è¡Œæ™‚é–“çš„è£é£¾å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start = time.time()
            result = await func(*args, **kwargs)
            elapsed = time.time() - start

            logger.info(
                f"â±ï¸ {operation_name} è€—æ™‚: {elapsed*1000:.0f}ms"
            )

            # å¦‚æœè¶…éé–¾å€¼ï¼Œç™¼å‡ºè­¦å‘Š
            if elapsed > 2.0:
                logger.warning(
                    f"âš ï¸ {operation_name} åŸ·è¡Œç·©æ…¢: {elapsed:.2f}s"
                )

            return result
        return wrapper
    return decorator

# ä½¿ç”¨
@measure_time("Genie æŸ¥è©¢")
async def query_genie(query: str):
    result = await genie_service.query(query)
    return result
```

### è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§

```python
import psutil
import os

def log_memory_usage():
    """è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()

    memory_mb = memory_info.rss / 1024 / 1024

    logger.info(f"ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨: {memory_mb:.0f} MB")

    # è­¦å‘Šé«˜è¨˜æ†¶é«”ä½¿ç”¨
    if memory_mb > 500:  # > 500 MB
        logger.warning(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜: {memory_mb:.0f} MB")

# å®šæœŸç›£æ§
async def memory_monitor_task():
    while True:
        log_memory_usage()
        await asyncio.sleep(300)  # æ¯ 5 åˆ†é˜
```

---

## 9. æ•ˆèƒ½åŸºæº–æ¸¬è©¦

### ç°¡å–®åŸºæº–æ¸¬è©¦

```python
import time
import asyncio

async def benchmark_function(func, iterations: int = 100):
    """åŸºæº–æ¸¬è©¦å‡½å¼æ•ˆèƒ½"""

    # æš–èº«
    await func()

    # æ¸¬é‡
    times = []
    for _ in range(iterations):
        start = time.time()
        await func()
        elapsed = time.time() - start
        times.append(elapsed)

    # çµ±è¨ˆ
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)

    print(f"å¹³å‡: {avg_time*1000:.0f}ms")
    print(f"æœ€å°: {min_time*1000:.0f}ms")
    print(f"æœ€å¤§: {max_time*1000:.0f}ms")

    return times

# ä½¿ç”¨
async def test_query():
    return await genie_service.query("SELECT 1")

await benchmark_function(test_query, iterations=100)
```

---

## 10. å„ªåŒ–æª¢æŸ¥æ¸…å–®

æ•ˆèƒ½å„ªåŒ–å‰æª¢æŸ¥ï¼š

- [ ] ä½¿ç”¨ HTTP é€£æ¥æ± ï¼ˆhttpx.AsyncClient é‡ç”¨ï¼‰
- [ ] å¯¦ä½œå¿«å–ç³»çµ±ï¼ˆæŸ¥è©¢ã€åœ–è¡¨ï¼‰
- [ ] ä¸¦ç™¼è™•ç†å¤šå€‹è«‹æ±‚ï¼ˆasyncio.gatherï¼‰
- [ ] æœƒè©±è‡ªå‹•æ¸…ç†ï¼ˆé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼ï¼‰
- [ ] æ—¥èªŒæ¡æ¨£ï¼ˆæ¸›å°‘ I/Oï¼‰
- [ ] é™åˆ¶å¿«å–å¤§å°ï¼ˆLRU + TTLï¼‰
- [ ] å¤§è³‡æ–™åˆ†é è™•ç†
- [ ] æ¸¬é‡é—œéµæ“ä½œæ™‚é–“
- [ ] ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
- [ ] åŸºæº–æ¸¬è©¦é©—è­‰å„ªåŒ–æ•ˆæœ

---

## å¿«é€Ÿåƒè€ƒ

### å„ªåŒ–ç­–ç•¥å„ªå…ˆç´š

| å„ªå…ˆç´š | ç­–ç•¥ | é æœŸæå‡ | å¯¦ä½œè¤‡é›œåº¦ |
|-------|------|---------|----------|
| ğŸ”´ é«˜ | HTTP é€£æ¥æ±  | 90% | ä½ |
| ğŸ”´ é«˜ | æŸ¥è©¢å¿«å– | 99% | ä½ |
| ğŸŸ¡ ä¸­ | ä¸¦ç™¼è™•ç† | 80% | ä¸­ |
| ğŸŸ¡ ä¸­ | æœƒè©±æ¸…ç† | é¿å… OOM | ä½ |
| ğŸŸ¢ ä½ | æ—¥èªŒæ¡æ¨£ | 15% | ä¸­ |
| ğŸŸ¢ ä½ | åœ–è¡¨å¿«å– | 99% | ä½ |

### æ•ˆèƒ½ç›®æ¨™

```
API å›æ‡‰æ™‚é–“ï¼ˆé¦–æ¬¡ï¼‰ï¼š< 1500ms
API å›æ‡‰æ™‚é–“ï¼ˆå¿«å–ï¼‰ï¼š< 50ms
è¨˜æ†¶é«”ä½¿ç”¨ï¼š< 300MB
ä¸¦ç™¼è«‹æ±‚ï¼š10-50 QPS
```

---

## åƒè€ƒè³‡æº

- [docs/architecture/optimization.md](../../../docs/architecture/optimization.md) - å®Œæ•´å„ªåŒ–æŒ‡å—
- [app/utils/cache_utils.py](../../../app/utils/cache_utils.py) - å¿«å–å¯¦ä½œ
- [app/utils/session_manager.py](../../../app/utils/session_manager.py) - æœƒè©±ç®¡ç†
