# ğŸš€ Databricks Genie æ©Ÿå™¨äºº - æ•ˆèƒ½å„ªåŒ–å»ºè­°

**æ—¥æœŸ:** 2026å¹´1æœˆ30æ—¥  
**åˆ†æç¯„åœ:** æ•´å€‹æ‡‰ç”¨ç¨‹å¼æ¶æ§‹  
**å„ªå…ˆç´š:** ä¼æ¥­ç´šç”Ÿç”¢ç’°å¢ƒ

---

## ğŸ“Š ç›®å‰æ•ˆèƒ½ç‹€æ…‹

| æŒ‡æ¨™ | ç‹€æ…‹ | å‚™è¨» |
|------|------|------|
| HTTP é€£æ¥æ±  | âœ… å·²å¯¦ç¾ | ä½¿ç”¨ aiohttp é€£æ¥é‡ç”¨ |
| ç”¨æˆ¶å¿«å– | âœ… å·²å¯¦ç¾ | LRU å¿«å–ï¼ˆ1000 å¤§å°ï¼‰|
| æ€§èƒ½æŒ‡æ¨™ | âœ… å·²å¯¦ç¾ | P50/P95 è¿½è¹¤ |
| æ—¥èªŒæ€§èƒ½ | âš ï¸ éœ€å„ªåŒ– | å¤§é‡æ—¥èªŒè¼¸å‡ºå¯èƒ½å½±éŸ¿æ€§èƒ½ |
| å…§å­˜ç®¡ç† | âš ï¸ éœ€ç›£æ§ | ç”¨æˆ¶æœƒè©±ç„¡è‡ªå‹•éæœŸ |
| æ•¸æ“šåº«é€£æ¥ | âœ… è‰¯å¥½ | ä½¿ç”¨ Databricks SDK |

---

## ğŸ¯ å„ªåŒ–å»ºè­°ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰

### å„ªå…ˆç´š 1ï¸âƒ£ï¼šæ—¥èªŒæ€§èƒ½å„ªåŒ–

#### 1.1 **ç•°æ­¥æ—¥èªŒå¯«å…¥** ğŸ”´ HIGH

**å•é¡Œ:** å¤§é‡çš„æ—¥èªŒè¨˜éŒ„ï¼ˆå°¤å…¶æ˜¯ `_log_api_response`ï¼‰æœƒé˜»å¡ä¸»ç·šç¨‹

**ç•¶å‰ä»£ç¢¼:**
```python
def _log_api_response(self, request_id: str, response_data: Dict, total_elapsed: float) -> None:
    logger.info(
        f"\n{'='*80}\n"
        f"[{request_id}] ğŸ“¤ API éŸ¿æ‡‰ - å®Œæ•´è¼¸å‡º\n"
        f"{self._format_json_for_logging(response_data)}\n"  # âš ï¸ å¤§é‡å­—ç¬¦ä¸²æ“ä½œ
        f"{'='*80}"
    )
```

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… æ–¹æ¡ˆ 1: ä½¿ç”¨éšŠåˆ—ç•°æ­¥å¯«å…¥æ—¥èªŒ
import queue
import threading

class AsyncLogger:
    def __init__(self):
        self.log_queue = queue.Queue()
        self.worker_thread = threading.Thread(target=self._worker, daemon=True)
        self.worker_thread.start()
    
    def _worker(self):
        """å¾Œå°ç·šç¨‹è™•ç†æ—¥èªŒ"""
        while True:
            try:
                log_entry = self.log_queue.get(timeout=1)
                if log_entry is None:
                    break
                logger.info(log_entry)
            except queue.Empty:
                continue
    
    async def log_async(self, message: str):
        """ç•°æ­¥æ—¥èªŒè¨˜éŒ„"""
        self.log_queue.put(message)

# âœ… æ–¹æ¡ˆ 2: æ¢ä»¶åŒ–è©³ç´°æ—¥èªŒ
def _log_api_response(self, request_id: str, response_data: Dict, total_elapsed: float) -> None:
    if os.environ.get('VERBOSE_LOGGING', '').lower() == 'true':
        logger.info(f"[{request_id}] ğŸ“¤ API éŸ¿æ‡‰å·²å®Œæˆ ({total_elapsed:.2f}s)")
    
    # åƒ…åœ¨ DEBUG æ¨¡å¼è¨˜éŒ„å®Œæ•´éŸ¿æ‡‰
    if os.environ.get('DEBUG_MODE', '').lower() == 'true':
        logger.debug(f"å®Œæ•´éŸ¿æ‡‰:\n{self._format_json_for_logging(response_data)}")
```

**é æœŸæ”¹é€²:**
- â¬†ï¸ æŸ¥è©¢éŸ¿æ‡‰æ™‚é–“ **æ¸›å°‘ 15-20%**
- â¬†ï¸ ååé‡ **æå‡ 10-15%**

**å¯¦ç¾é›£åº¦:** â­â­â­ (ä¸­ç­‰)

---

#### 1.2 **æ—¥èªŒæ¡æ¨£** ğŸŸ¡ MEDIUM

**å•é¡Œ:** æ¯å€‹æŸ¥è©¢éƒ½è©³ç´°è¨˜éŒ„æ•ˆèƒ½æŒ‡æ¨™ï¼Œå°é«˜æµé‡æœ‰å½±éŸ¿

**ç•¶å‰ä»£ç¢¼:**
```python
if self.metrics.total_queries % 100 == 0:
    self.metrics.log_stats()  # 100 å€‹æŸ¥è©¢æ‰è¨˜éŒ„ä¸€æ¬¡
```

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… æ–¹æ¡ˆ: åŸºæ–¼æ™‚é–“å’ŒæŸ¥è©¢æ•¸çš„æ··åˆæ¡æ¨£
class SamplingLogger:
    def __init__(self, sample_rate: float = 0.01, time_interval: int = 60):
        self.sample_rate = sample_rate  # 1% æ¡æ¨£ç‡
        self.time_interval = time_interval  # 60 ç§’
        self.last_log_time = time.time()
    
    def should_log_stats(self, query_count: int) -> bool:
        """æ±ºå®šæ˜¯å¦è¨˜éŒ„çµ±è¨ˆä¿¡æ¯"""
        import random
        
        # æ™‚é–“æ¢ä»¶ï¼šæ¯ N ç§’è¨˜éŒ„ä¸€æ¬¡
        if time.time() - self.last_log_time >= self.time_interval:
            self.last_log_time = time.time()
            return True
        
        # æŸ¥è©¢æ¢ä»¶ï¼šæŒ‰ç™¾åˆ†æ¯”æ¡æ¨£
        if random.random() < self.sample_rate and query_count % 10 == 0:
            return True
        
        return False

# åœ¨ genie_service.py ä½¿ç”¨
sampling_logger = SamplingLogger(sample_rate=0.01, time_interval=60)

if sampling_logger.should_log_stats(self.metrics.total_queries):
    self.metrics.log_stats()
```

**é æœŸæ”¹é€²:**
- â¬‡ï¸ æ—¥èªŒè¼¸å‡º **æ¸›å°‘ 99%**ï¼ˆ1% æ¡æ¨£ï¼‰
- â¬†ï¸ I/O è² è¼‰ **æ¸›å°‘ 50-70%**

**å¯¦ç¾é›£åº¦:** â­â­ (ç°¡å–®)

---

### å„ªå…ˆç´š 2ï¸âƒ£ï¼šå…§å­˜ç®¡ç†å„ªåŒ–

#### 2.1 **ç”¨æˆ¶æœƒè©±è‡ªå‹•éæœŸæ¸…ç†** ğŸ”´ HIGH

**å•é¡Œ:** ç”¨æˆ¶æœƒè©±ç„¡é™æœŸå­˜å„²ï¼Œé€ æˆå…§å­˜æ´©æ¼

**ç•¶å‰ä»£ç¢¼:**
```python
class MyBot(ActivityHandler):
    def __init__(self, genie_service: GenieService):
        self.user_sessions: Dict[str, UserSession] = {}  # ç„¡é™å¢é•·
```

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… æ–¹æ¡ˆ: LRU å¿«å– + TTL çµ„åˆ
from functools import lru_cache
import time

class SessionManager:
    """å¸¶ TTL å’Œ LRU æ¸…ç†çš„æœƒè©±ç®¡ç†å™¨"""
    
    def __init__(self, max_sessions: int = 1000, ttl_seconds: int = 86400):
        self.user_sessions: Dict[str, UserSession] = {}
        self.max_sessions = max_sessions
        self.ttl_seconds = ttl_seconds  # 24 å°æ™‚ TTL
        self.access_times: Dict[str, float] = {}
    
    def get_session(self, user_id: str) -> Optional[UserSession]:
        """ç²å–æœƒè©±ä¸¦æ›´æ–°è¨ªå•æ™‚é–“"""
        if user_id not in self.user_sessions:
            return None
        
        # æª¢æŸ¥ TTL
        last_access = self.access_times.get(user_id, 0)
        if time.time() - last_access > self.ttl_seconds:
            self.delete_session(user_id)
            return None
        
        # æ›´æ–°è¨ªå•æ™‚é–“
        self.access_times[user_id] = time.time()
        return self.user_sessions[user_id]
    
    def add_session(self, user_id: str, session: UserSession) -> None:
        """æ·»åŠ æœƒè©±ï¼Œå¦‚æœè¶…éé™åˆ¶å‰‡æ¸…ç†æœ€èˆŠçš„"""
        if len(self.user_sessions) >= self.max_sessions:
            # ç§»é™¤æœ€èˆŠçš„è¨ªå•çš„æœƒè©±
            oldest_user = min(self.access_times, key=self.access_times.get)
            self.delete_session(oldest_user)
        
        self.user_sessions[user_id] = session
        self.access_times[user_id] = time.time()
    
    def delete_session(self, user_id: str) -> None:
        """åˆªé™¤æœƒè©±"""
        if user_id in self.user_sessions:
            del self.user_sessions[user_id]
            del self.access_times[user_id]
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†éæœŸæœƒè©±: {user_id}")
    
    def cleanup_expired(self) -> int:
        """æ¸…ç†æ‰€æœ‰éæœŸæœƒè©±ï¼Œè¿”å›æ¸…ç†æ•¸é‡"""
        current_time = time.time()
        expired_users = [
            user_id for user_id, access_time in self.access_times.items()
            if current_time - access_time > self.ttl_seconds
        ]
        
        for user_id in expired_users:
            self.delete_session(user_id)
        
        return len(expired_users)

# âœ… åœ¨ app.py ä¸­ä½¿ç”¨
class MyBot(ActivityHandler):
    def __init__(self, genie_service: GenieService):
        self.genie_service = genie_service
        self.session_manager = SessionManager(max_sessions=1000, ttl_seconds=86400)
        # ...

# âœ… å®šæœŸæ¸…ç†ä»»å‹™
async def cleanup_task():
    """æ¯å°æ™‚é‹è¡Œä¸€æ¬¡æœƒè©±æ¸…ç†"""
    while True:
        await asyncio.sleep(3600)  # æ¯å°æ™‚
        count = BOT.session_manager.cleanup_expired()
        logger.info(f"âœ… å·²æ¸…ç† {count} å€‹éæœŸæœƒè©±")

# åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚è¨»å†Š
async def on_startup(app: web.Application):
    asyncio.create_task(cleanup_task())
```

**é æœŸæ”¹é€²:**
- â¬‡ï¸ å…§å­˜ä½¿ç”¨ **æ¸›å°‘ 60-80%**ï¼ˆé•·æœŸé‹è¡Œï¼‰
- âœ… é˜²æ­¢ OOMï¼ˆOut of Memoryï¼‰å´©æ½°
- âœ… å®Œå…¨è‡ªå‹•åŒ–ï¼Œç„¡éœ€äººå·¥å¹²é 

**å¯¦ç¾é›£åº¦:** â­â­â­ (ä¸­ç­‰)

---

#### 2.2 **ç”¨æˆ¶ä¸Šä¸‹æ–‡å¿«å–å¤§å°å„ªåŒ–** ğŸŸ¡ MEDIUM

**å•é¡Œ:** LRU å¿«å–å¤§å°å›ºå®šç‚º 1000ï¼Œåœ¨é«˜æµé‡ä¸‹å¯èƒ½ä¸è¶³

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… å‹•æ…‹èª¿æ•´å¿«å–å¤§å°
class AdaptiveLRUCache:
    """æ ¹æ“šå…§å­˜ä½¿ç”¨æƒ…æ³å‹•æ…‹èª¿æ•´ LRU å¿«å–å¤§å°"""
    
    def __init__(self, initial_size: int = 1000):
        self.cache = {}
        self.max_size = initial_size
        self.access_order = deque()  # è¿½è¹¤è¨ªå•é †åº
    
    def get(self, key: str):
        if key in self.cache:
            self.access_order.remove(key)
            self.access_order.append(key)
            return self.cache[key]
        return None
    
    def put(self, key: str, value: Any) -> None:
        if key in self.cache:
            self.access_order.remove(key)
        elif len(self.cache) >= self.max_size:
            # ç§»é™¤æœ€èˆŠçš„æ¢ç›®
            oldest = self.access_order.popleft()
            del self.cache[oldest]
        
        self.cache[key] = value
        self.access_order.append(key)
    
    def adjust_size_based_on_memory(self) -> None:
        """æ ¹æ“šå…§å­˜ä½¿ç”¨æƒ…æ³èª¿æ•´å¿«å–å¤§å°"""
        import psutil
        
        mem_percent = psutil.virtual_memory().percent
        
        if mem_percent > 80:  # å…§å­˜è¶…é 80%
            self.max_size = max(100, int(self.max_size * 0.8))
            logger.warning(f"âš ï¸ å…§å­˜å£“åŠ›é«˜ï¼Œæ¸›å°‘å¿«å–å¤§å°åˆ° {self.max_size}")
        elif mem_percent < 50:  # å…§å­˜ä½æ–¼ 50%
            self.max_size = min(5000, int(self.max_size * 1.2))
            logger.info(f"âœ… å…§å­˜å……è¶³ï¼Œå¢åŠ å¿«å–å¤§å°åˆ° {self.max_size}")
```

**é æœŸæ”¹é€²:**
- ğŸ¯ è‡ªé©æ‡‰å…§å­˜ä½¿ç”¨
- â¬†ï¸ é«˜æµé‡ä¸‹å¿«å–å‘½ä¸­ç‡æå‡

**å¯¦ç¾é›£åº¦:** â­â­â­ (ä¸­ç­‰)

---

### å„ªå…ˆç´š 3ï¸âƒ£ï¼šAPI èª¿ç”¨å„ªåŒ–

#### 3.1 **è«‹æ±‚æ‰¹é‡åŒ–** ğŸŸ¡ MEDIUM

**å•é¡Œ:** ç„¡æ³•å° Databricks é€²è¡Œæ‰¹é‡æŸ¥è©¢

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… å¯¦ç¾è«‹æ±‚æ‰¹éšŠåˆ—
from collections import deque
import asyncio

class RequestBatcher:
    """æ‰¹é‡åŒ– API è«‹æ±‚ä»¥æé«˜ååé‡"""
    
    def __init__(self, batch_size: int = 5, batch_timeout: float = 0.5):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.queue: deque = deque()
        self.pending_futures: List = []
    
    async def add_request(self, request_data: Dict) -> Any:
        """æ·»åŠ è«‹æ±‚åˆ°éšŠåˆ—ä¸¦ç­‰å¾…çµæœ"""
        future = asyncio.Future()
        self.queue.append((request_data, future))
        
        # å¦‚æœé”åˆ°æ‰¹æ¬¡å¤§å°ï¼Œç«‹å³è™•ç†
        if len(self.queue) >= self.batch_size:
            await self._process_batch()
        
        return await future
    
    async def _process_batch(self) -> None:
        """è™•ç†ä¸€å€‹æ‰¹æ¬¡çš„è«‹æ±‚"""
        batch = []
        futures = []
        
        while self.queue and len(batch) < self.batch_size:
            request_data, future = self.queue.popleft()
            batch.append(request_data)
            futures.append(future)
        
        if not batch:
            return
        
        # æ‰¹é‡ç™¼é€è«‹æ±‚
        logger.info(f"ğŸ“¦ è™•ç†æ‰¹æ¬¡: {len(batch)} å€‹è«‹æ±‚")
        
        try:
            results = await self._send_batch(batch)
            for future, result in zip(futures, results):
                future.set_result(result)
        except Exception as e:
            for future in futures:
                future.set_exception(e)
    
    async def _send_batch(self, batch: List[Dict]) -> List[Any]:
        """ç™¼é€æ‰¹æ¬¡è«‹æ±‚"""
        # é€™è£¡å¯¦ç¾å¯¦éš›çš„ API èª¿ç”¨é‚è¼¯
        pass
```

**é æœŸæ”¹é€²:**
- â¬†ï¸ ååé‡ **æå‡ 30-50%**ï¼ˆé©ç”¨æ–¼é«˜ä¸¦ç™¼å ´æ™¯ï¼‰
- â¬‡ï¸ å»¶é² **æ¸›å°‘ 10-20%**

**å¯¦ç¾é›£åº¦:** â­â­â­â­ (è¤‡é›œ)

---

#### 3.2 **é€£æ¥è¶…æ™‚å„ªåŒ–** ğŸ”´ HIGH

**å•é¡Œ:** ç„¡è¶…æ™‚é…ç½®ï¼Œæ…¢é€Ÿé€£æ¥æœƒå µå¡

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… è¨­ç½®åˆç†çš„è¶…æ™‚é…ç½®
@asynccontextmanager
async def get_http_session(self):
    """å¸¶å„ªåŒ–è¶…æ™‚çš„ HTTP Session"""
    if not self._http_session or self._http_session.closed:
        timeout = aiohttp.ClientTimeout(
            total=30,      # ç¸½è¶…æ™‚ï¼š30 ç§’
            connect=5,     # é€£æ¥è¶…æ™‚ï¼š5 ç§’
            sock_read=10,  # è®€å–è¶…æ™‚ï¼š10 ç§’
            sock_connect=5 # Socket é€£æ¥ï¼š5 ç§’
        )
        self._http_session = aiohttp.ClientSession(
            timeout=timeout,
            connector=aiohttp.TCPConnector(
                limit=100,           # é€£æ¥æ± å¤§å°
                limit_per_host=30,   # æ¯å€‹ host æœ€å¤š 30 å€‹é€£æ¥
                ttl_dns_cache=300    # DNS å¿«å– 5 åˆ†é˜
            )
        )
    
    try:
        yield self._http_session
    except asyncio.TimeoutError:
        logger.error("âŒ HTTP è«‹æ±‚è¶…æ™‚ï¼Œæ­£åœ¨é—œé–‰é€£æ¥")
        await self._http_session.close()
        self._http_session = None
        raise
```

**é æœŸæ”¹é€²:**
- âœ… é˜²æ­¢ç„¡é™æœŸç­‰å¾…
- â¬‡ï¸ éŒ¯èª¤æ¢å¾©æ™‚é–“ **æ¸›å°‘ 50%**

**å¯¦ç¾é›£åº¦:** â­â­ (ç°¡å–®)

---

### å„ªå…ˆç´š 4ï¸âƒ£ï¼šæ•¸æ“šè™•ç†å„ªåŒ–

#### 4.1 **JSON åºåˆ—åŒ–å„ªåŒ–** ğŸŸ¡ MEDIUM

**å•é¡Œ:** å¤§å‹ JSON éŸ¿æ‡‰çš„é‡è¤‡åºåˆ—åŒ–å’Œæ ¼å¼åŒ–

**ç•¶å‰ä»£ç¢¼:**
```python
def _format_json_for_logging(self, data: Any, indent: int = 2) -> str:
    """æ¯æ¬¡éƒ½é‡æ–°æ ¼å¼åŒ–å¤§å‹ JSON"""
    return json.dumps(data, indent=indent, ensure_ascii=False)
```

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… ä½¿ç”¨ simplejson å’Œæµå¼è™•ç†
import simplejson

class OptimizedJsonHandler:
    """å„ªåŒ–çš„ JSON è™•ç†"""
    
    @staticmethod
    def dump_minimal(data: Dict) -> str:
        """æœ€å°åŒ–è¼¸å‡ºï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰"""
        return simplejson.dumps(data, separators=(',', ':'), ensure_ascii=False)
    
    @staticmethod
    def dump_pretty(data: Dict, truncate_length: int = 1000) -> str:
        """ç¾åŒ–è¼¸å‡ºï¼Œæˆªæ–·å¤§å­—æ®µï¼ˆèª¿è©¦ï¼‰"""
        def truncate_dict(obj):
            if isinstance(obj, dict):
                return {k: truncate_dict(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [truncate_dict(item) for item in obj[:10]]  # é™åˆ¶åˆ—è¡¨å¤§å°
            elif isinstance(obj, str) and len(obj) > truncate_length:
                return obj[:truncate_length] + "..."
            return obj
        
        truncated = truncate_dict(data)
        return simplejson.dumps(truncated, indent=2, ensure_ascii=False)
    
    @staticmethod
    async def stream_write(data: Dict, file_path: str) -> None:
        """éåŒæ­¥æµå¼å¯«å…¥å¤§å‹ JSON"""
        import aiofiles
        
        async with aiofiles.open(file_path, 'w') as f:
            await f.write(simplejson.dumps(data))
```

**é æœŸæ”¹é€²:**
- â¬‡ï¸ JSON åºåˆ—åŒ–æ™‚é–“ **æ¸›å°‘ 30-40%**
- â¬‡ï¸ å…§å­˜ä½¿ç”¨ **æ¸›å°‘ 20%**

**å¯¦ç¾é›£åº¦:** â­â­ (ç°¡å–®)

---

#### 4.2 **å›æ‡‰å£“ç¸®** ğŸŸ¡ MEDIUM

**å•é¡Œ:** å¤§å‹å›æ‡‰æœªå£“ç¸®ï¼Œæµªè²»ç¶²è·¯é »å¯¬

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… åœ¨ app.py æ·»åŠ  gzip ä¸­ä»‹è»Ÿé«”
from aiohttp_compress import GZipMiddleware

def init_func(argv):
    APP = web.Application(
        middlewares=[
            aiohttp_error_middleware,
            GZipMiddleware(minimum_size=1024)  # 1KB ä»¥ä¸Šé€²è¡Œå£“ç¸®
        ]
    )
    # ...
```

**é æœŸæ”¹é€²:**
- â¬‡ï¸ ç¶²è·¯å‚³è¼¸ **æ¸›å°‘ 70-80%**ï¼ˆå–æ±ºæ–¼å…§å®¹ï¼‰
- â¬†ï¸ ç”¨æˆ¶é«”é©—æ”¹å–„ï¼ˆæ›´å¿«çš„åŠ è¼‰ï¼‰

**å¯¦ç¾é›£åº¦:** â­ (éå¸¸ç°¡å–®)

---

### å„ªå…ˆç´š 5ï¸âƒ£ï¼šç›£æ§å’Œè¨ºæ–·

#### 5.1 **æ•ˆèƒ½è¿½è¹¤å„€è¡¨æ¿** ğŸŸ¡ MEDIUM

**å»ºè­°æ–¹æ¡ˆ:**
```python
# âœ… å»ºç«‹æ•ˆèƒ½æŒ‡æ¨™ç«¯é»
from datetime import datetime

async def get_performance_metrics(request: web.Request) -> web.Response:
    """ç²å–æ•ˆèƒ½æŒ‡æ¨™ JSON"""
    stats = GENIE_SERVICE.metrics.get_stats()
    
    return web.json_response({
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'metrics': stats,
        'sessions': {
            'active': len(BOT.session_manager.user_sessions),
            'cached': len(BOT._user_context_cache),
        },
        'memory': {
            'usage_mb': get_memory_usage(),
            'connections': GENIE_SERVICE._http_session.connector.limit if GENIE_SERVICE._http_session else 0,
        }
    })

# åœ¨ init_func ä¸­æ·»åŠ è·¯ç”±
def init_func(argv):
    APP = web.Application(middlewares=[aiohttp_error_middleware])
    APP.router.add_get("/api/metrics", get_performance_metrics)
    # ...
```

**é æœŸæ”¹é€²:**
- âœ… å¯¦æ™‚æ€§èƒ½å¯è¦–åŒ–
- âœ… å¿«é€Ÿè­˜åˆ¥ç“¶é ¸

**å¯¦ç¾é›£åº¦:** â­â­ (ç°¡å–®)

---

## ğŸ“ˆ å„ªåŒ–æ•ˆæœé ä¼°

| å„ªåŒ–é … | å½±éŸ¿ | é›£åº¦ | é æœŸæ”¹å–„ |
|------|------|------|--------|
| ç•°æ­¥æ—¥èªŒå¯«å…¥ | é«˜ | ä¸­ | P95 å»¶é² â†“ 15-20% |
| æ—¥èªŒæ¡æ¨£ | ä¸­ | ä½ | æ—¥èªŒè¼¸å‡º â†“ 99% |
| æœƒè©±è‡ªå‹•éæœŸ | é«˜ | ä¸­ | å…§å­˜ä½¿ç”¨ â†“ 60-80% |
| å¿«å–å‹•æ…‹èª¿æ•´ | ä¸­ | ä¸­ | å‘½ä¸­ç‡ â†‘ 10-15% |
| è«‹æ±‚æ‰¹é‡åŒ– | é«˜ | é«˜ | ååé‡ â†‘ 30-50% |
| é€£æ¥è¶…æ™‚é…ç½® | é«˜ | ä½ | éŒ¯èª¤æ¢å¾© â†“ 50% |
| JSON åºåˆ—åŒ–å„ªåŒ– | ä¸­ | ä½ | åºåˆ—åŒ–æ™‚é–“ â†“ 30-40% |
| å›æ‡‰å£“ç¸® | ä¸­ | ä½ | ç¶²è·¯å‚³è¼¸ â†“ 70-80% |

---

## ğŸ¯ å»ºè­°å¯¦æ–½è¨ˆåŠƒ

### **ç¬¬ 1 é€±**ï¼ˆå¿«é€Ÿå‹åˆ©ï¼‰
- [ ] å¯¦ç¾æ—¥èªŒæ¡æ¨£ï¼ˆ15 åˆ†é˜ï¼‰
- [ ] æ·»åŠ é€£æ¥è¶…æ™‚é…ç½®ï¼ˆ30 åˆ†é˜ï¼‰
- [ ] éƒ¨ç½² gzip å£“ç¸®ï¼ˆ10 åˆ†é˜ï¼‰
- [ ] å‰µå»ºæ•ˆèƒ½æŒ‡æ¨™ç«¯é»ï¼ˆ1 å°æ™‚ï¼‰

### **ç¬¬ 2-3 é€±**ï¼ˆæ ¸å¿ƒæ”¹é€²ï¼‰
- [ ] å¯¦ç¾æœƒè©±è‡ªå‹•éæœŸæ¸…ç†ï¼ˆ2-3 å°æ™‚ï¼‰
- [ ] ç•°æ­¥æ—¥èªŒå¯«å…¥ï¼ˆ2-3 å°æ™‚ï¼‰
- [ ] JSON åºåˆ—åŒ–å„ªåŒ–ï¼ˆ1-2 å°æ™‚ï¼‰

### **ç¬¬ 4-6 é€±**ï¼ˆé«˜ç´šå„ªåŒ–ï¼‰
- [ ] è«‹æ±‚æ‰¹é‡åŒ–ï¼ˆ4-6 å°æ™‚ï¼‰
- [ ] å‹•æ…‹å¿«å–èª¿æ•´ï¼ˆ2-3 å°æ™‚ï¼‰
- [ ] æ€§èƒ½æ¸¬è©¦å’Œèª¿å„ªï¼ˆ3-4 å°æ™‚ï¼‰

---

## ğŸ§ª æ•ˆèƒ½æ¸¬è©¦æ–¹æ¡ˆ

```python
# âœ… æ€§èƒ½åŸºæº–æ¸¬è©¦
import time
import statistics

async def benchmark():
    """é‹è¡Œæ•ˆèƒ½åŸºæº–æ¸¬è©¦"""
    durations = []
    
    for i in range(1000):
        start = time.time()
        # æ¨¡æ“¬æŸ¥è©¢
        await GENIE_SERVICE.ask(
            "test query",
            space_id=CONFIG.SPACE_ID,
            user_session=mock_session
        )
        durations.append(time.time() - start)
    
    print(f"""
    === æ•ˆèƒ½åŸºæº–æ¸¬è©¦çµæœ ===
    å¹³å‡: {statistics.mean(durations):.2f}s
    ä¸­ä½æ•¸: {statistics.median(durations):.2f}s
    P95: {sorted(durations)[int(len(durations)*0.95)]:.2f}s
    P99: {sorted(durations)[int(len(durations)*0.99)]:.2f}s
    """)
```

---

## ğŸ“ å¯¦æ–½æª¢æŸ¥æ¸…å–®

- [ ] è©•ä¼°ç•¶å‰æ•ˆèƒ½åŸºæº–
- [ ] å¯¦æ–½ç¬¬ 1 é€±çš„å¿«é€Ÿå‹åˆ©
- [ ] ç›£æ§æ”¹é€²æ•ˆæœ
- [ ] é€æ­¥å¯¦æ–½é€²éšå„ªåŒ–
- [ ] å®šæœŸæ€§èƒ½åŸºæº–æ¸¬è©¦
- [ ] æ–‡æª”åŒ–å„ªåŒ–è®Šæ›´
- [ ] åœ˜éšŠåŸ¹è¨“ï¼ˆæœ€ä½³å¯¦è¸ï¼‰

---

## ğŸ“š åƒè€ƒè³‡æº

- [aiohttp æ€§èƒ½èª¿å„ª](https://docs.aiohttp.org/en/stable/client_advanced.html)
- [Python æ€§èƒ½æœ€ä½³å¯¦è¸](https://realpython.com/python-performance/)
- [éåŒæ­¥ Python æ¨¡å¼](https://docs.python.org/3/library/asyncio.html)
- [Databricks SDK æ€§èƒ½](https://docs.databricks.com/en/sdk-guide/index.html)

---

**å®Œæˆæ™‚é–“:** 2026å¹´1æœˆ30æ—¥  
**ä¸‹ä¸€æ­¥:** é¸æ“‡å„ªå…ˆç´š 1ï¸âƒ£ çš„é …ç›®é–‹å§‹å¯¦æ–½
